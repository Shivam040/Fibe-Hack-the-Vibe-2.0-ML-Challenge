{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV with latin1 encoding, skipping bad lines\n",
    "test = pd.read_csv(test_path, delimiter=',', escapechar='\\\\', header=0, on_bad_lines='skip', encoding='latin1')\n",
    "\n",
    "# Function to remove non-utf8 characters from text\n",
    "def remove_non_utf8(text):\n",
    "    # Use regex to remove characters that are not valid in utf-8\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# Apply the function to the 'text' column to clean non-utf8 characters\n",
    "test['text'] = test['text'].apply(remove_non_utf8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the rows whose Index column is empty\n",
    "test = test[test['Index'].notnull() & (test['Index'].str.strip() != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2labels = {0: 'academic interests', 1: 'arts and culture', 2: 'automotives', 3: 'books and literature', 4: 'business and finance',\n",
    " 5: 'careers', 6: 'family and relationships', 7: 'food and drinks', 8: 'health', 9: 'healthy living', 10: 'hobbies and interests',\n",
    " 11: 'home and garden', 12: 'movies', 13: 'music and audio', 14: 'news and politics', 15: 'personal finance', 16: 'pets',\n",
    " 17: 'pharmaceuticals, conditions, and symptoms', 18: 'real estate', 19: 'shopping', 20: 'sports', 21: 'style and fashion',\n",
    " 22: 'technology and computing', 23: 'television', 24: 'travel', 25: 'video gaming'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(gpu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/1model\"\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "nlp = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer, device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_patterns(text):\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].apply(remove_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(test['text'])\n",
    "B = pd.DataFrame(test['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=nlp(A[:], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the list of predictions to a tensor\n",
    "values_tensor = torch.tensor(values)\n",
    "pred = []\n",
    "# Loop through each prediction\n",
    "for i in range(len(A)):\n",
    "    # Get the index of the maximum value for the current example\n",
    "    max_index = values_tensor[i].argmax().item()  # .item() to get a Python number from a tensor\n",
    "    pred.append(id2labels[max_index])\n",
    "    # Print the predicted label using id2labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['target'] = pred_df['target'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['Index'] = B['Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('Prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIBE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
