{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo_QFRjnBOGl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, BertTokenizerFast\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmIjdvTVBOGn"
      },
      "outputs": [],
      "source": [
        "train_path = '../dataset/train.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAGVF0HfBOGn"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(train_path, delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9HpBH8MBOGo"
      },
      "outputs": [],
      "source": [
        "threshold = 10\n",
        "value_counts = train['target'].value_counts()\n",
        "train = train[train['target'].isin(value_counts[value_counts >= threshold].index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iELbAVsrBOGo"
      },
      "outputs": [],
      "source": [
        "train_1 = train.groupby('target').apply(lambda x: x.sample(16000)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9CI5mNqBOGo"
      },
      "outputs": [],
      "source": [
        "train_1 = train_1.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtUYtRKeBOGp"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71s-k_UUBOGp"
      },
      "outputs": [],
      "source": [
        "def remove_patterns(text):\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga6l5K-MBOGp"
      },
      "outputs": [],
      "source": [
        "train_1['text'] = train_1['text'].apply(remove_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tci_r_RyBOGp"
      },
      "outputs": [],
      "source": [
        "train_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbneWTqtBOGp"
      },
      "outputs": [],
      "source": [
        "train_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnKJvCLvBOGp"
      },
      "outputs": [],
      "source": [
        "lables = train['target'].unique().tolist()\n",
        "labeles = [s.strip() for s in lables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlkTvRzmBOGp"
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = len(lables)\n",
        "\n",
        "id2labels={id:label for id, label in enumerate(lables)}\n",
        "labels2id={label:id for id, label in enumerate(lables)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP9YJEB1BOGp"
      },
      "outputs": [],
      "source": [
        "id2labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf3J8SdZBOGp"
      },
      "outputs": [],
      "source": [
        "train_1['labels']= train_1.target.map(lambda x: labels2id[x.strip()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG5OsQGFBOGp"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\", num_labels=NUM_LABELS, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkaQI3E4BOGp"
      },
      "outputs": [],
      "source": [
        "model.id2labels = id2labels\n",
        "model.labels2id = labels2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa4FijaIBOGq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiD1mq5RBOGq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.set_per_process_memory_fraction(0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N52CQrQFBOGq"
      },
      "outputs": [],
      "source": [
        "model.to(gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C43GZDDmBOGq"
      },
      "outputs": [],
      "source": [
        "train_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKeUSH8KBOGq"
      },
      "outputs": [],
      "source": [
        "train_1 = train_1.sample(frac=1)\n",
        "train_1 = train_1.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3kfhj_ZBOGq"
      },
      "outputs": [],
      "source": [
        "train_3 = train_1[:300000].groupby('target').apply(lambda x: x.sample(10000)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_lDucvOBOGq"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(train_3[['text']])\n",
        "Y_train = pd.DataFrame(train_3['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0s7SW_sBOGq"
      },
      "outputs": [],
      "source": [
        "train_2 = train_1[300000:350000].groupby('target').apply(lambda x: x.sample(200)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cvm03FZBOGq"
      },
      "outputs": [],
      "source": [
        "X_valid = pd.DataFrame(train_2[['text']])\n",
        "Y_valid = pd.DataFrame(train_2['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ69017FBOGq"
      },
      "outputs": [],
      "source": [
        "X_test = pd.DataFrame(train_1['text'][390000:])\n",
        "Y_test = pd.DataFrame(train_1['labels'][390000:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EEX71MmBOGq"
      },
      "outputs": [],
      "source": [
        "X_train = X_train['text'].tolist()\n",
        "X_valid = X_valid['text'].tolist()\n",
        "X_test = X_test['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlCI7noiBOGq"
      },
      "outputs": [],
      "source": [
        "Y_train = Y_train['labels'].tolist()\n",
        "Y_valid = Y_valid['labels'].tolist()\n",
        "Y_test = Y_test['labels'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGsRSCBdBOGq"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(X_valid, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNVWlUQWBOGq"
      },
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encoding, labels):\n",
        "        self.encoding = encoding\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx])  for key, val in self.encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_encodings, Y_train)\n",
        "val_dataloader = DataLoader(val_encodings, Y_valid)\n",
        "test_dataloader = DataLoader(test_encodings, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scbuLcuqBOGr"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ =  precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc =  accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'F1': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SATS6psEBOGr"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/results',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.0001,\n",
        "    logging_strategy='steps',\n",
        "    learning_rate= 0.00006,\n",
        "\n",
        "    logging_dir='/logs',\n",
        "    logging_steps=500,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        "    save_strategy='steps',\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLZxmN5pBOGr"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataloader,\n",
        "    eval_dataset=val_dataloader,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBefPPqlBOGr"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmrcIVMUBOGs"
      },
      "outputs": [],
      "source": [
        "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataloader]]\n",
        "pd.DataFrame(q, index=[\"train\", \"val\", \"test\"]).iloc[:,:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr16Tpk6BOGs"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    texts = tokenizer(text, padding=True,truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model(**texts)\n",
        "\n",
        "    probs = outputs[0].softmax(1)\n",
        "    pred_label_idx = probs.argmax()\n",
        "\n",
        "    pred_label = model.config.id2label[pred_label_idx.item()]\n",
        "\n",
        "    return probs, pred_label_idx, pred_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCK6mCM9BOGs"
      },
      "outputs": [],
      "source": [
        "model_path = \"model/1model\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96NiRBGdBOGs"
      },
      "source": [
        "## Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSdX0tO0BOGy"
      },
      "outputs": [],
      "source": [
        "torch.cuda.set_per_process_memory_fraction(0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAi-uXPxBOGy"
      },
      "outputs": [],
      "source": [
        "model_path = \"model/1model\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "nlp = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer, device=gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPXEJ7jtBOGy"
      },
      "outputs": [],
      "source": [
        "test_path = '../dataset/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT_Yk3WqBOGz"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOJ5ar2sBOGz"
      },
      "outputs": [],
      "source": [
        "test['text'] = test['text'].apply(remove_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVqGSve2BOGz"
      },
      "outputs": [],
      "source": [
        "test.drop('Word Count', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmiRXrsXBOG0"
      },
      "outputs": [],
      "source": [
        "A = pd.DataFrame(test['text'])\n",
        "B = pd.DataFrame(test['Index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExotysrfBOG0"
      },
      "outputs": [],
      "source": [
        "A = A['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyuSW_nOBOG0"
      },
      "outputs": [],
      "source": [
        "values=nlp(A[:], truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d5KSorqBOG0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Convert the list of predictions to a tensor\n",
        "values_tensor = torch.tensor(values)\n",
        "pred = []\n",
        "\n",
        "for i in range(len(A)):\n",
        "    # Get the index of the maximum value for the current example\n",
        "    max_index = values_tensor[i].argmax().item()  # .item() to get a Python number from a tensor\n",
        "    pred.append(id2labels[max_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta2XcCxFBOG1"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(pred, columns=[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T-QZc5ZBOG1"
      },
      "outputs": [],
      "source": [
        "pred_df['target'] = pred_df['target'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgrEgEZ7BOG1"
      },
      "outputs": [],
      "source": [
        "pred_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9gg0tHrBOG1"
      },
      "outputs": [],
      "source": [
        "pred_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jll9ORk7BOG1"
      },
      "outputs": [],
      "source": [
        "pred_df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7MnAE_3BOG2"
      },
      "outputs": [],
      "source": [
        "B.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7DjSuUeBOG2"
      },
      "outputs": [],
      "source": [
        "pred_df['Index'] = B['Index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb68nZd-BOG2"
      },
      "outputs": [],
      "source": [
        "pred_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAnjjgpSBOG2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "FIBE",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}